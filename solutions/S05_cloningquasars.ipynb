{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import astropy\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb20e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from astroML.datasets import fetch_dr7_quasar\n",
    "\n",
    "# Fetch the quasar data\n",
    "quasars = fetch_dr7_quasar()\n",
    "\n",
    "# select the first 10000 points\n",
    "quasars = quasars[:10000]\n",
    "\n",
    "data = quasars['redshift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b073fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data,bins=50,histtype='step',density=True,label='original data');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695cff2",
   "metadata": {},
   "source": [
    "A numpy histogram object out of the data with `density=True` and `bins=50` is a tuple of bin heights and bin edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac71c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(data, bins=100,density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f252f",
   "metadata": {},
   "source": [
    "### Cloning by rejection sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c679780",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data,bins=50,histtype='step',density=True,label='original data');\n",
    "\n",
    "# make a simple histogram object\n",
    "counts, bins = np.histogram(data, bins=50, density=True)\n",
    "maxh = counts.max() # find the maximum\n",
    "\n",
    "# Make a scipy.stats random variable object from a histogram\n",
    "# This is a great hack!\n",
    "disth = scipy.stats.rv_histogram((counts,bins))\n",
    "\n",
    "# Let's do it manually again\n",
    "N = 100000 # trials\n",
    "q = np.random.uniform(-10, 30, N) # proposed points\n",
    "u = np.random.uniform(0, maxh, N) # uniform draws\n",
    "\n",
    "mask = u<=disth.pdf(q) # assess whether u <= q(x_i)\n",
    "\n",
    "monte_carlo = q[mask] # reject all points that don't pass, using masking\n",
    "\n",
    "plt.hist(monte_carlo, bins=50, density=True,histtype='step',label='cloned data 1');\n",
    "\n",
    "### But scipy has it already implemented \n",
    "plt.hist(disth.rvs(size=N),bins=50,density=True,histtype='step',label='cloned data 2');\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e6d88",
   "metadata": {},
   "source": [
    "### Cloning by inverse transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393989ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data,bins=50,histtype='step',density=True,label='original data');\n",
    "\n",
    "\n",
    "# make a simple histogram object\n",
    "counts, bins = np.histogram(data, bins=50, density=True)\n",
    "bin_mids = (bins[1:] + bins[:-1]) / 2 # mid location of bins\n",
    " \n",
    "simple_cdf = np.cumsum(counts) / np.sum(counts) # very simply cumulative sum\n",
    "\n",
    "# set up an interpolation of the inverse cumulative distribution\n",
    "tck = scipy.interpolate.interp1d(simple_cdf, bin_mids)\n",
    "\n",
    "# sample evenly along the cumulative distribution, and interpolate\n",
    "# little hack to make sure no points are generated outside interpolation range.\n",
    "# not ideal\n",
    "u = np.random.uniform(min(simple_cdf),max(simple_cdf), 10000) \n",
    "x_sample = tck(u)\n",
    "\n",
    "plt.hist(x_sample, bins=100, density=True, histtype='step',label='cloned data');\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c392a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c64497be",
   "metadata": {},
   "source": [
    "## Now some cosmology...\n",
    "\n",
    "Let's try to assume that quasars are distributed uniformly in comoving volume in the Universe. Seems fair...\n",
    "\n",
    "We use the cosmological parameters as measured by the Plack satellite, which is a flat $\\Lambda$ CDM model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ff566",
   "metadata": {},
   "outputs": [],
   "source": [
    "astropy.cosmology.Planck18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383316d3",
   "metadata": {},
   "source": [
    "Let's put things in a class now. Note **lazy loading**, which is a terrific tecnique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca4985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class uniformredshift(object):\n",
    "    def __init__(self,zmax):\n",
    "        ''' Lazy loading...'''\n",
    "        self._norm = None\n",
    "        self._pdfmax = None\n",
    "        self.zmax=zmax\n",
    "\n",
    "    def _eval(self,z_vals):\n",
    "        '''Unnormalized pdf'''\n",
    "        return ((4.*np.pi*astropy.cosmology.Planck18.differential_comoving_volume(z_vals).value))\n",
    "\n",
    "\n",
    "    def norm(self):\n",
    "        '''Compute normalization'''\n",
    "        if self._norm is None:\n",
    "            self._norm = scipy.integrate.quad( self._eval, 0, self.zmax)[0]\n",
    "        return self._norm\n",
    "\n",
    "\n",
    "    def eval(self,z_vals):\n",
    "        return self._eval(z_vals)/self.norm()\n",
    "\n",
    "        return np.array(zsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshiftpdf = uniformredshift(zmax = 5)\n",
    "\n",
    "z = np.linspace(0,5,100)\n",
    "plt.plot(z,2.4*redshiftpdf.eval(z)) ###   Arbitrary normalization, just matching by eye\n",
    "\n",
    "plt.hist(data,bins=50,histtype='step',density=True,label='original data');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f8220",
   "metadata": {},
   "source": [
    "They are not distributed unifiormly in comoving volume! I mean, they are but only at low redshits.\n",
    "\n",
    "Surely are all quasars created equally? But do we see them equally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487a35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ee0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
